{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Lane Finding Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration\n",
    "\n",
    "#### Camera calibration involves computing the camera matrix and distortion coefficients. \n",
    "\n",
    "The code for this step is contained in the first code cell of the IPython notebook located in \"./advanced_lane_lines.ipynb\". \n",
    "\n",
    "The idea is that you take pictures of known shape such as a black-white chessboard. You can use `cv2.findChessboardCorners()` function to find all corners where black and white intersects. These corner points, an array of (x,y), are used to create my so-called image points (i.e. an array of array of points `imgpoints`). \n",
    "\n",
    "The \"object points\", on the other hand, are the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.  \n",
    "\n",
    "I then used the two arrays `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  Lastlt, I applied this distortion correction to the test image using the `cv2.undistort()` function and show the original and undistorted images side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "nx = 9 #the number of inside corners in x\n",
    "ny = 6 #the number of inside corners in y\n",
    "board_size = (nx, ny)\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "for imgfile in images:\n",
    "    img = cv2.imread(imgfile)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, board_size, None)\n",
    "    if ret == True:\n",
    "        ## print('found chessboard: ', imgfile)\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)    \n",
    "\n",
    "# Save the camera calibration matrix and distortion coefficients\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "dist_pickle[\"objpoints\"] = objpoints\n",
    "dist_pickle[\"imgpoints\"] = imgpoints\n",
    "pickle.dump( dist_pickle, open( \"wide_dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "# Testing \n",
    "img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# img2 = cv2.drawChessboardCorners(img, board_size, corners, ret)\n",
    "\n",
    "def draw_two_imgs(img1, img2, title1='Original Image', title2='Undistorted Image'):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(title1, fontsize=24)\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(title2, fontsize=24)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "draw_two_imgs(img, undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open( \"wide_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "draw_two_imgs(img, undistorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (single images)\n",
    "\n",
    "#### 1. Camera calibration on a test image\n",
    "\n",
    "Since we saved our camera calibration matrix and distortion coefficients in a pickle file, we can easily read these parameters back and undistort another image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test2.jpg')\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "draw_two_imgs(img, undistorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a thresholded binary image\n",
    "\n",
    "I used a combination of color space and gradient thresholds to generate a binary image. For color thresholding, I first converted the image from RGB colorspace to HLS colorspace. This line is then used to threshold the _s_ chanel `s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1` Gradient thresholding step is similar and done on the Sobel x gradient `sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1`. I also compute the combined bianry with `combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1`. At the end is an example of my output for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "def pipeline(img, s_thresh=(120, 255),sx_thresh=(20, 255),l_thresh=(40,255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold s channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold l channel\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    \n",
    "    # Combine the three binary thresholds\n",
    "    binary = np.zeros_like(sxbinary)\n",
    "    binary[((l_binary == 1) & (s_binary == 1) | (sxbinary==1))] = 1\n",
    "    # combined_binary = 255*np.dstack((binary,binary,binary)).astype('uint8')\n",
    "    return color_binary, binary\n",
    "    \n",
    "result, combined_binary = pipeline(image)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "ax2.imshow(result)\n",
    "ax2.set_title('Color Binary', fontsize=40)\n",
    "\n",
    "#combined_binary = 255*np.dstack((binary,binary,binary)).astype('uint8')\n",
    "ax3.imshow(combined_binary, cmap='gray')\n",
    "ax3.set_title('Combined Binary', fontsize=40)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Perspective transform\n",
    "\n",
    "The code for my perspective transform includes a function called `warper()`, which appears in lines 1 through 12 in the code block below. The `warper()` function takes as inputs an image (`img`), as well as source (`src`) and destination (`dst`) points. I chose the hardcoded source and destination points by overlaying a trapezoid on one of the test images. I verified that my perspective transform was working as expected by drawing the `src` and `dst` points onto a test image and its warped counterpart to verify that the lines appear parallel in the warped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def warper(img, src, dst, debug=False):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)    \n",
    "    MInv = cv2.getPerspectiveTransform(dst, src)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size , flags=cv2.INTER_LINEAR)    \n",
    "\n",
    "    if debug:\n",
    "        cv2.line(img, tuple(src[0]), tuple(src[1]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(img, tuple(src[1]), tuple(src[2]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(img, tuple(src[2]), tuple(src[3]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(img, tuple(src[3]), tuple(src[0]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(warped, tuple(dst[0]), tuple(dst[1]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(warped, tuple(dst[1]), tuple(dst[2]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(warped, tuple(dst[2]), tuple(dst[3]), color=[255,0,0], thickness=2)\n",
    "        cv2.line(warped, tuple(dst[3]), tuple(dst[0]), color=[255,0,0], thickness=2)\n",
    "    \n",
    "    return warped, M, MInv\n",
    "\n",
    "corners = np.float32([[200,720],[585,460],[698,460],[1100,720]])\n",
    "top_left=np.array([corners[0,0],0])\n",
    "top_right=np.array([corners[3,0],0])\n",
    "offset=[100, 0]\n",
    "src = np.float32([corners[0],corners[1],corners[2],corners[3]])\n",
    "dst = np.float32([corners[0]+offset,top_left+offset,top_right-offset,corners[3]-offset])\n",
    "print(dst)\n",
    "# Test it out\n",
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "warped, M, MInv = warper(undist, src, dst, debug=True)\n",
    "\n",
    "draw_two_imgs(undist, warped, title2='Undistorted and Warped Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further test our warper matrix, I am going to run it on all test images and save to an output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    image_name=os.path.split(fname)[1]\n",
    "    warped = cv2.warpPerspective(undist, M, (img.shape[1], img.shape[0]) , flags=cv2.INTER_LINEAR)  \n",
    "    out_name = 'test_images_warped/'+'warped_'+image_name\n",
    "    cv2.imwrite(out_name, warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Polynomial fit of the lane-line pixels\n",
    "\n",
    "First, I am defining a few helper function to tie my image process pipepline together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def region_mask(img):\n",
    "    shape = img.shape\n",
    "    vertices = np.array([[(0,0),(shape[1],0),(shape[1],0),(6*shape[1]/7,shape[0]),\n",
    "                      (shape[1]/7,shape[0]), (0,0)]],dtype=np.int32)\n",
    "\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def undistort(img):\n",
    "    result = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return result\n",
    "\n",
    "def warp(img):\n",
    "    result = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]) , flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def undist_pipeline_warp(img):\n",
    "    undist = undistort(img)\n",
    "    color_binary, binary = pipeline(img,s_thresh=(110, 255),sx_thresh=(25, 255))\n",
    "    combined_binary = 255*np.dstack((binary,binary,binary)).astype('uint8')\n",
    "    result = warp(combined_binary)\n",
    "    # result = region_mask(result)\n",
    "    return result, combined_binary\n",
    "\n",
    "img = plt.imread('test_images/test1.jpg')\n",
    "warped_binary, intermediate_binary = undist_pipeline_warp(img)\n",
    "\n",
    "draw_two_imgs(img, warped_binary, title2='Warped Binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Using histogram to identify lane-line starting point\n",
    "\n",
    "Now that we have our warped binary image (see above, on the left side). I will plot a histogram of the pixels along all the columns in the lower half of the image like this. Since in our warp function, we created warped image with all three channels (the values are identical from channel to channel), we just need to grab the first channel to perform the histgoram calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_channel = warped_binary[:,:,0]\n",
    "histogram = np.sum(single_channel[int(single_channel.shape[0]/2):,:], axis=0)\n",
    "print(histogram.shape)\n",
    "print(np.argmax(histogram))\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Sliding window line detection\n",
    "\n",
    "Once we identify the starting position of both left and right lane line at the bottom. We are going to use sliding window to move up and find all pixels belonging to the lines. Once we located the lane line pixels, we can then use their x and y pixel positions to fit a second order polynomial curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sliding_window(binary_warped):\n",
    "    global out_img\n",
    "    out_img = np.copy(binary_warped)\n",
    "\n",
    "    single_channel = binary_warped[:,:,0]\n",
    "    histogram = np.sum(single_channel[int(single_channel.shape[0]/2):,:], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    \n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    ## print('midpoint, left, right:', midpoint, leftx_base, rightx_base)\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped_binary.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped_binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),color=[0,255,0], thickness=2)\n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),color=[0,255,0], thickness=2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "    lanes_detected = False\n",
    "\n",
    "    if leftx.shape[0] > 1 and rightx.shape[0] > 1:\n",
    "        lanes_detected = True\n",
    "        \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return lanes_detected, left_fit, right_fit\n",
    "    \n",
    "lanes_detected, left_fit, right_fit = sliding_window(warped_binary)\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Lane detection on subsequent frames\n",
    "\n",
    "Once we detected the lane lines on the first image frame, we don't have to use the sliding window anymore because the lane lines should be generally around where they were from the previous frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subsequent_frame(binary_warped, left_fit, right_fit):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    lanes_detected = False\n",
    "    if leftx.shape[0] > 1 and rightx.shape[0] > 1:\n",
    "        lanes_detected = True\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return lanes_detected, left_fit, right_fit \n",
    "\n",
    "img = plt.imread('test_images/test1.jpg')\n",
    "binary, _= undist_pipeline_warp(img)\n",
    "binary_warped = binary[:,:,0]\n",
    "\n",
    "detected, left_fit, right_fit = subsequent_frame(binary_warped, left_fit, right_fit)\n",
    "\n",
    "# Create an image to draw on and an image to show the selection window\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "window_img = np.zeros_like(out_img)\n",
    "# Color in left and right line pixels\n",
    "#out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "#out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "margin = 100\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Measuring Curvature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate some fake data to represent lane-line pixels\n",
    "quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "ploty_sample = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "# For each y position generate random x position within +/-50 pix\n",
    "# of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "leftx_sample = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                              for y in ploty_sample])\n",
    "rightx_sample = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                for y in ploty_sample])\n",
    "\n",
    "def calculate_curvature(leftx, rightx, ploty):\n",
    "    #leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    #rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Plot up the fake data\n",
    "    mark_size = 3\n",
    "    plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "    plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(0, 720)\n",
    "    plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "    plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "    plt.gca().invert_yaxis() # to visualize as we do the images\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    print('Curvature in pixel space: ', left_curverad, right_curverad)\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    print('Curvature in world space: ', left_curverad, 'm', right_curverad, 'm')\n",
    "\n",
    "#calculate_curvature(leftx_sample, rightx_sample, ploty_sample)\n",
    "calculate_curvature(left_fitx, right_fitx, ploty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Lane Area Overlay\n",
    "\n",
    "First, we create an empty image to draw the lines on. Then we recast the x and y points into usable format for cv2.fillPoly() and draw the fitted lanes onto the warped blank image. We use the previsouly calculated inverse perspective matrix MInv to warp the lane image back to the original image space. The last step is to combine the lane image and camera-corrected original image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def overlay_lane_lines(img,left_fitx,right_fitx,yvals):\n",
    "    lanefit_image = np.zeros_like(img).astype(np.uint8)\n",
    "\n",
    "    left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    points = np.hstack((left, right))\n",
    "    cv2.fillPoly(lanefit_image, np.int_([points]), (0, 255, 0))\n",
    "\n",
    "    undist = undistort(img)\n",
    "    inverse_warp = cv2.warpPerspective(lanefit_image, MInv, (img.shape[1], img.shape[0])) \n",
    "    result = cv2.addWeighted(undist, 1, inverse_warp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "img = plt.imread('test_images/test1.jpg')\n",
    "overlay = overlay_lane_lines(img, left_fitx, right_fitx, ploty)\n",
    "\n",
    "draw_two_imgs(img, overlay, title2='Overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pipeline (video)\n",
    "\n",
    "#### 5.1 Process image frame\n",
    "\n",
    "I created a function called `process_image`, that will take an image as parameter and run through the pipeline we have developed so far. I used image test4.jpg to test my pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "#import imageio\n",
    "#imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lanes_detected = None\n",
    "left_fit = []\n",
    "right_fit = []\n",
    "def process_image(img):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    global lanes_detected, left_fit, right_fit\n",
    "    image = undistort(img)\n",
    "    warped_binary, intermediate_binary = undist_pipeline_warp(img)\n",
    "    if lanes_detected is None:\n",
    "        ## print('Lanes not detected yet, try sliding window')\n",
    "        lanes_detected, left_fit, right_fit = sliding_window(warped_binary)\n",
    "\n",
    "    if lanes_detected is True:\n",
    "        lanes_detected, left_fit, right_fit = subsequent_frame(warped_binary, left_fit, right_fit)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        image = overlay_lane_lines(img, left_fitx, right_fitx, ploty)\n",
    "    else:\n",
    "        ## print('Not detect, try next frame')\n",
    "        lanes_detected = None\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = plt.imread('test_images/test4.jpg')\n",
    "overlay = process_image(img)\n",
    "\n",
    "draw_two_imgs(img, overlay, title2='Overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Saving video\n",
    "\n",
    "Here we use moviepy's VideoFileClip to grab each frame and feed it through my developed pipeline. The output video file is save in `project_video_out.mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'project_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "processed_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time processed_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
